#!/usr/bin/env python
# coding: utf-8

# In[1]:


get_ipython().run_cell_magic('writefile', 'dataanalysis.py', '\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport streamlit as st\nimport pickle\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.impute import KNNImputer\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n# Streamlit app\nst.title(\'Protein Data Analysis\')\n\n# Upload CSV file\nuploaded_file = st.file_uploader("Choose a CSV file", type="csv")\n\nif uploaded_file is not None:\n    # Load the dataset\n    data = pd.read_csv(uploaded_file)\n    \n    # Display basic information about the dataset\n    st.subheader(\'Data Overview\')\n    st.write(data.info())\n    st.write(data.head())\n\n    # Drop the \'MouseID\' column\n    data = data.drop(\'MouseID\', axis=1)\n\n    # Encode categorical variables\n    data[\'Genotype\'] = data[\'Genotype\'].map({\'Control\': 0, \'Ts65Dn\': 1})\n    data[\'Treatment\'] = data[\'Treatment\'].map({\'Saline\': 0, \'Memantine\': 1})\n    data[\'Behavior\'] = data[\'Behavior\'].map({\'C/S\': 0, \'S/C\': 1})\n\n    # Label encode the \'class\' column\n    encode = LabelEncoder().fit(data[\'class\'])\n    data[\'class\'] = encode.transform(data[\'class\'])\n\n    # Save the encoder using pickle\n    with open(\'enc.pickle\', \'wb\') as f:\n        pickle.dump(encode, f)\n\n    # Handle missing values\n    missing_values = data.isnull().mean() * 100\n    missing_values = missing_values[missing_values > 0].sort_values(ascending=False)\n    st.subheader(\'Missing Values\')\n    st.write(missing_values)\n\n    # Impute missing values using KNN imputer\n    if missing_values.sum() > 0:\n        imputer = KNNImputer(n_neighbors=5, weights=\'uniform\', missing_values=np.nan)\n        data_imputed = imputer.fit_transform(data)\n        data = pd.DataFrame(data_imputed, columns=data.columns)\n\n    st.write(f\'Total missing values after imputation: {data.isnull().sum().sum()}\')\n\n    # Normalize the data\n    numerical_cols = data.select_dtypes(include=[\'float64\', \'int64\']).columns\n    scaler = StandardScaler()\n    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n\n    # Split the data into features and labels\n    X = data.drop(\'class\', axis=1)\n    y = data[\'class\']\n    \n    # Ensure the target variable is discrete\n    if not np.issubdtype(y.dtype, np.integer):\n        y = y.astype(int)\n\n    # Correlation Analysis\n    st.subheader(\'Correlation Matrix\')\n    corr_matrix = data.corr()\n    fig, ax = plt.subplots(figsize=(12, 10))\n    sns.heatmap(corr_matrix, annot=False, cmap=\'coolwarm\', linewidths=0.5, ax=ax)\n    st.pyplot(fig)\n\n    # Mutual Information\n    st.subheader(\'Mutual Information\')\n    numerical_features = data.drop(columns=[\'Genotype\', \'Treatment\', \'Behavior\', \'class\'])\n    target = data[\'class\']\n\n    # Ensure the target variable is discrete\n    if not np.issubdtype(target.dtype, np.integer):\n        target = target.astype(int)\n\n    mi = mutual_info_classif(numerical_features, target, discrete_features=False)\n    mi_df = pd.DataFrame({\'Feature\': numerical_features.columns, \'Mutual Information\': mi})\n    mi_df = mi_df.sort_values(by=\'Mutual Information\', ascending=False)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    sns.barplot(x=\'Mutual Information\', y=\'Feature\', data=mi_df, ax=ax)\n    st.pyplot(fig)\n\n    # Feature Importance from RandomForest\n    st.subheader(\'Feature Importance from RandomForest\')\n    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf_model.fit(numerical_features, target)\n    importances = rf_model.feature_importances_\n\n    feature_importance_df = pd.DataFrame({\'Feature\': numerical_features.columns, \'Importance\': importances})\n    feature_importance_df = feature_importance_df.sort_values(by=\'Importance\', ascending=False)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    sns.barplot(x=\'Importance\', y=\'Feature\', data=feature_importance_df, ax=ax)\n    st.pyplot(fig)\n\nelse:\n    st.write("Please upload a CSV file to proceed.")\n')


# In[ ]:


get_ipython().system('streamlit run dataanalysis.py')


# In[ ]:




